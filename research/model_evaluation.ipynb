{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Portable\\\\OneDrive\\\\Desktop\\\\Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Portable\\\\OneDrive\\\\Desktop\\\\Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(r\"artifacts\\model\\trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 128)           66560     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                1625      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117619 (459.45 KB)\n",
      "Trainable params: 117619 (459.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_sequences(data: np.ndarray):\n",
    "    x, y = [], []\n",
    "    for i in range(60, len(data)):\n",
    "        x.append(data[i - 60:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    x = np.array(x).reshape((-1, 60, 1))\n",
    "    y = np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-25 22:45:43,512: INFO: 1069016221: Real-time data fetched successfully.]\n",
      "[2024-11-25 22:45:43,513: INFO: 1069016221: Real-time data fetched for symbol: IBM]\n",
      "[2024-11-25 22:45:43,513: INFO: 1069016221: Real-time data scaled.]\n"
     ]
    }
   ],
   "source": [
    "scaled_data, dataset = evaluator.fetch_and_preprocess_real_time_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = _create_sequences(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47297297, 0.33783784, 0.47297297, 0.40540541, 0.40540541,\n",
       "       0.47297297, 0.92567568, 0.65540541, 0.67567568, 0.49324324,\n",
       "       0.5       , 0.47297297, 0.47972973, 0.31756757, 0.47297297,\n",
       "       0.50675676, 0.47972973, 0.54054054, 0.31756757, 0.47972973,\n",
       "       0.50777027, 0.54054054, 0.51351351, 0.50675676, 0.47972973,\n",
       "       0.47972973, 0.47972973, 0.43918919, 0.54054054, 0.40540541,\n",
       "       0.55398649, 0.54054054, 0.54054054, 0.54054054, 0.54054054,\n",
       "       0.43918919, 0.54054054, 0.54054054, 0.54054054, 0.55405405])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 60, 1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34927928],\n",
       "       [0.36449555],\n",
       "       [0.37387547],\n",
       "       [0.3841495 ],\n",
       "       [0.39180982],\n",
       "       [0.39732075],\n",
       "       [0.4038615 ],\n",
       "       [0.42974225],\n",
       "       [0.45719242],\n",
       "       [0.48548228],\n",
       "       [0.505279  ],\n",
       "       [0.5183438 ],\n",
       "       [0.5248106 ],\n",
       "       [0.52662927],\n",
       "       [0.51843333],\n",
       "       [0.51006734],\n",
       "       [0.50338507],\n",
       "       [0.49726802],\n",
       "       [0.4944725 ],\n",
       "       [0.48495683],\n",
       "       [0.4778215 ],\n",
       "       [0.47375503],\n",
       "       [0.47348833],\n",
       "       [0.47484496],\n",
       "       [0.47700578],\n",
       "       [0.47846118],\n",
       "       [0.479297  ],\n",
       "       [0.4796082 ],\n",
       "       [0.47783253],\n",
       "       [0.4788536 ],\n",
       "       [0.4762055 ],\n",
       "       [0.47727832],\n",
       "       [0.48035207],\n",
       "       [0.4847792 ],\n",
       "       [0.489966  ],\n",
       "       [0.4954372 ],\n",
       "       [0.49662554],\n",
       "       [0.4989123 ],\n",
       "       [0.5018234 ],\n",
       "       [0.5051058 ]], dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47297297, 0.33783784, 0.47297297, 0.40540541, 0.40540541,\n",
       "       0.47297297, 0.92567568, 0.65540541, 0.67567568, 0.49324324,\n",
       "       0.5       , 0.47297297, 0.47972973, 0.31756757, 0.47297297,\n",
       "       0.50675676, 0.47972973, 0.54054054, 0.31756757, 0.47972973,\n",
       "       0.50777027, 0.54054054, 0.51351351, 0.50675676, 0.47972973,\n",
       "       0.47972973, 0.47972973, 0.43918919, 0.54054054, 0.40540541,\n",
       "       0.55398649, 0.54054054, 0.54054054, 0.54054054, 0.54054054,\n",
       "       0.43918919, 0.54054054, 0.54054054, 0.54054054, 0.55405405])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(scaled_data: np.ndarray, training_data_len: int, dataset: np.ndarray):\n",
    "    try:\n",
    "        x_test, y_test = _create_sequences(scaled_data)\n",
    "        print(f\"x_test shape: {x_test.shape}\")\n",
    "        model = load_model()  \n",
    "        predictions = model.predict(x_test)\n",
    "        predictions = predictions.flatten()\n",
    "        y_test = self.scaler.inverse_transform(y_test)\n",
    "        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
    "        \n",
    "        logger.info(f\"Testing complete. RMSE: {rmse}\")\n",
    "        return rmse, predictions\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during model testing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    model_path: Path\n",
    "    sequence_length: int\n",
    "    mlflow_uri: str\n",
    "    symbol: str\n",
    "    interval: str\n",
    "    outputsize: str\n",
    "    base_url: str\n",
    "    api_key: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StockPricePrediction.utils.common import read_yaml, create_directories\n",
    "from src.StockPricePrediction.constants import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath: Path):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config['model_evaluation_params']\n",
    "        \n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            model_path=Path(config['model_path']),\n",
    "            sequence_length=config['sequence_length'],\n",
    "            mlflow_uri=config['mlflow_uri'],\n",
    "            symbol=config['symbol'],\n",
    "            interval=config['interval'],\n",
    "            outputsize=config['outputsize'],\n",
    "            base_url=config['api_endpoint'],\n",
    "            api_key=os.getenv('ALPHA_VANTAGE_API_KEY'),\n",
    "\n",
    "        )\n",
    "        \n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests  # Added missing import\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler  # Added missing import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from src.StockPricePrediction import logger\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))  # Initialized scaler\n",
    "\n",
    "    def fetch_real_time_data(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            params = {\n",
    "                \"function\": \"TIME_SERIES_INTRADAY\",\n",
    "                \"symbol\": self.config.symbol,\n",
    "                \"interval\": self.config.interval,\n",
    "                \"apikey\": self.config.api_key,\n",
    "                \"datatype\": \"json\"\n",
    "            }\n",
    "            response = requests.get(self.config.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            key = f\"Time Series ({self.config.interval})\"\n",
    "            if key not in data:\n",
    "                raise ValueError(f\"Unexpected response format: {data}\")\n",
    "\n",
    "            # Extract and format data\n",
    "            time_series = data[key]\n",
    "            df = pd.DataFrame.from_dict(time_series, orient=\"index\")\n",
    "            df.columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "            df = df.astype(float)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.sort_index(inplace=True)\n",
    "            logger.info(\"Real-time data fetched successfully.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching real-time data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def fetch_and_preprocess_real_time_data(self) -> np.ndarray:\n",
    "        try:\n",
    "            # Fetch real-time data\n",
    "            real_time_data = self.fetch_real_time_data()\n",
    "            logger.info(f\"Real-time data fetched for symbol: {self.config.symbol}\")\n",
    "\n",
    "            # Use the 'close' column for predictions\n",
    "            dataset = real_time_data[['close']].values\n",
    "\n",
    "            # Scale data\n",
    "            scaled_data = self.scaler.fit_transform(dataset)  # Use saved scaler if available\n",
    "            logger.info(\"Real-time data scaled.\")\n",
    "            return scaled_data, dataset\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching and preprocessing real-time data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def test_model_real_time(self, scaled_data: np.ndarray):\n",
    "        try:\n",
    "            # Create sequences\n",
    "            x_real_time, _ = self._create_sequences(scaled_data)\n",
    "\n",
    "            # Predict\n",
    "            model = load_model(self.config.model_path)  # Load model dynamically\n",
    "            predictions = model.predict(x_real_time)\n",
    "            \n",
    "            predictions = self.scaler.inverse_transform(predictions)\n",
    "\n",
    "            logger.info(\"Real-time model testing complete.\")\n",
    "            return predictions\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during real-time model testing: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_sequences(self, data: np.ndarray):\n",
    "        x, y = [], []\n",
    "        for i in range(60, len(data)):\n",
    "            x.append(data[i - 60:i, 0])\n",
    "            y.append(data[i, 0])\n",
    "        x = np.array(x).reshape((-1, 60, 1))\n",
    "        y = np.array(y)\n",
    "        return x, y\n",
    "\n",
    "    def test_model(self, scaled_data: np.ndarray, training_data_len: int, dataset: np.ndarray):\n",
    "        try:\n",
    "            x_test, y_test = self._create_sequences(scaled_data)\n",
    "            print(f\"x_test shape: {x_test.shape}\")\n",
    "\n",
    "            model = load_model(self.config.model_path)  \n",
    "\n",
    "            predictions = model.predict(x_test)\n",
    "            predictions = self.scaler.inverse_transform(predictions)\n",
    "            predictions = predictions.flatten()\n",
    "            y_test = self.scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "            print(f\"prediction mean: {predictions.mean()}\")\n",
    "            print(f\"y_test mean: {y_test.mean()}\")\n",
    "            rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
    "            \n",
    "            logger.info(f\"Testing complete. RMSE: {rmse}\")\n",
    "            return rmse, predictions\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during model testing: {e}\")\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    def log_to_mlflow(self, rmse, predictions):        \n",
    "        model = load_model(self.config.model_path)  \n",
    "\n",
    "        try:\n",
    "            mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            print(\"Tracking URI: \", mlflow.get_tracking_uri())\n",
    "            with mlflow.start_run():\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"RMSE\", rmse)\n",
    "                # Log parameters\n",
    "                if tracking_url_type_store != \"file\":\n",
    "                    # track in the remote server\n",
    "                    print(\"tracking url: \",tracking_url_type_store)\n",
    "                    print(\"***remote***\\n\")\n",
    "                    # Log model\n",
    "                    mlflow.keras.log_model(model, artifact_path=\"model\")\n",
    "                else:\n",
    "                    # track in the local\n",
    "                    print(\"***local***\\n\")\n",
    "                    mlflow.keras.log_model(model, \"model\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging to MLflow: {e}\")\n",
    "            raise\n",
    "\n",
    "    def save_rmse(self, rmse: float):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(self.config.rmse_path), exist_ok=True)\n",
    "            with open(self.config.rmse_path, 'w') as f:\n",
    "                f.write(str(rmse))\n",
    "            logger.info(f\"RMSE saved to {self.config.rmse_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving RMSE: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-26 18:33:34,548: INFO: common: yaml file: config\\config.yaml loaded successfully]\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager(config_filepath=CONFIG_FILE_PATH)\n",
    "evaluation_config = config_manager.get_model_evaluation_config()\n",
    "evaluator = ModelEvaluator(config=evaluation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-26 18:34:52,329: INFO: 1115350102: Real-time data fetched successfully.]\n"
     ]
    }
   ],
   "source": [
    "data = evaluator.fetch_real_time_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-26 18:35:05,373: INFO: 1115350102: Real-time data fetched successfully.]\n",
      "[2024-11-26 18:35:05,373: INFO: 1115350102: Real-time data fetched for symbol: IBM]\n",
      "[2024-11-26 18:35:05,389: INFO: 1115350102: Real-time data scaled.]\n"
     ]
    }
   ],
   "source": [
    "scaled_data, dataset = evaluator.fetch_and_preprocess_real_time_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-26 18:35:07,096: INFO: 1618695276: Testing model on real-time data...]\n",
      "2/2 [==============================] - 2s 65ms/step\n",
      "[2024-11-26 18:35:09,986: INFO: 1115350102: Real-time model testing complete.]\n"
     ]
    }
   ],
   "source": [
    "# Test model on real-time data\n",
    "logger.info(\"Testing model on real-time data...\")\n",
    "predictions = evaluator.test_model_real_time(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (40, 60, 1)\n",
      "2/2 [==============================] - 1s 10ms/step\n",
      "prediction mean: 226.0263671875\n",
      "y_test mean: 225.818075\n",
      "[2024-11-26 18:35:15,198: INFO: 1115350102: Testing complete. RMSE: 0.3591865693837794]\n"
     ]
    }
   ],
   "source": [
    "rmse, test_predictions = evaluator.test_model(scaled_data, len(scaled_data), dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get('MLFLOW_TRACKING_URI')\n",
    "os.environ.get(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ.get(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: https://dagshub.com/BouazizOmar/Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle.mlflow\n",
      "MLFLOW_TRACKING_USERNAME: BouazizOmar\n",
      "MLFLOW_TRACKING_PASSWORD: a3c5b006173123d93ef056eb8b6f9fde0792be3f\n"
     ]
    }
   ],
   "source": [
    "# Verify the variables (optional)\n",
    "print(\"MLFLOW_TRACKING_URI:\", os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "print(\"MLFLOW_TRACKING_USERNAME:\", os.environ.get(\"MLFLOW_TRACKING_USERNAME\"))\n",
    "print(\"MLFLOW_TRACKING_PASSWORD:\", os.environ.get(\"MLFLOW_TRACKING_PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-26 18:35:31,381: INFO: 3386568819: Logging results to MLflow...]\n",
      "Tracking URI:  https://dagshub.com/BouazizOmar/Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/26 18:35:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking url:  https\n",
      "***remote***\n",
      "\n",
      "[2024-11-26 18:35:42,591: INFO: builder_impl: Assets written to: C:\\Users\\Portable\\AppData\\Local\\Temp\\tmpllu2k1_w\\model\\data\\model\\assets]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Logging results to MLflow...\")\n",
    "try:\n",
    "    model = load_model(evaluation_config.model_path)\n",
    "    evaluator.log_to_mlflow(model=model, rmse=rmse, predictions=test_predictions)\n",
    "    logger.info(\"Logged to MLflow successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error logging to MLflow: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from src.StockPricePrediction.components.model_evaluation_mlflow import ModelEvaluator\n",
    "from src.StockPricePrediction.config.configuration import ConfigurationManager\n",
    "from src.StockPricePrediction.constants import CONFIG_FILE_PATH\n",
    "from src.StockPricePrediction import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 11:45:55,149: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-11-27 11:45:56,854: INFO: model_evaluation_mlflow: Real-time data fetched successfully.]\n",
      "[2024-11-27 11:45:57,486: INFO: model_evaluation_mlflow: Real-time data fetched successfully.]\n",
      "[2024-11-27 11:45:57,487: INFO: model_evaluation_mlflow: Real-time data fetched for symbol: IBM]\n",
      "[2024-11-27 11:45:57,517: INFO: model_evaluation_mlflow: Real-time data scaled.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize ConfigurationManager\n",
    "config_manager = ConfigurationManager(config_filepath=CONFIG_FILE_PATH)\n",
    "evaluation_config = config_manager.get_model_evaluation_config()\n",
    "\n",
    "# Initialize Pipeline\n",
    "evaluator = ModelEvaluator(config=evaluation_config)\n",
    "data = evaluator.fetch_real_time_data()\n",
    "scaled_data, dataset = evaluator.fetch_and_preprocess_real_time_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 11:47:01.089 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Portable\\anaconda3\\envs\\MLOpsProject\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (40, 60, 1)\n",
      "2/2 [==============================] - 1s 0s/step\n",
      "prediction mean: 228.95394897460938\n",
      "y_test mean: 228.86881750000003\n",
      "[2024-11-27 11:47:03,629: INFO: model_evaluation_mlflow: Testing complete. RMSE: 0.34327656665254136]\n",
      "Tracking URI:  https://dagshub.com/BouazizOmar/Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle.mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/27 11:47:06 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking url:  https\n",
      "***remote***\n",
      "\n",
      "[2024-11-27 11:47:11,377: INFO: builder_impl: Assets written to: C:\\Users\\Portable\\AppData\\Local\\Temp\\tmp6lgk3r5h\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/27 11:47:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/27 11:49:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run placid-mink-441 at: https://dagshub.com/BouazizOmar/Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle.mlflow/#/experiments/0/runs/c52d534b197e4beab3586339130c7346.\n",
      "2024/11/27 11:49:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/BouazizOmar/Automated-Stock-Price-Prediction-Pipeline-A-Complete-MLOps-Lifecycle.mlflow/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 11:49:02,468: INFO: 1628663338: Logged to MLflow successfully.]\n"
     ]
    }
   ],
   "source": [
    "# Streamlit App\n",
    "st.title(\"Stock Price Prediction with LSTM\")\n",
    "st.markdown(\"\"\"\n",
    "This application predicts the next stock price using a trained LSTM model. It also logs metrics and models to MLflow.\n",
    "\"\"\")\n",
    "rmse, test_predictions = evaluator.test_model(scaled_data, len(scaled_data), dataset)\n",
    "\n",
    "# Display current stock price\n",
    "st.subheader(\"Current Stock Price\")\n",
    "try:\n",
    "    latest_close_price = data[\"close\"].iloc[-1]\n",
    "    st.write(f\"**Current Stock Price ({evaluation_config.symbol}):** ${latest_close_price:.2f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error fetching current stock price: {e}\")\n",
    "    st.error(\"Could not fetch the current stock price. Check the logs for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 11:55:06,488: INFO: model_evaluation_mlflow: Real-time data fetched successfully.]\n",
      "[2024-11-27 11:55:06,495: INFO: model_evaluation_mlflow: Real-time data fetched for symbol: IBM]\n",
      "[2024-11-27 11:55:06,529: INFO: model_evaluation_mlflow: Real-time data scaled.]\n"
     ]
    }
   ],
   "source": [
    "scaled_data, dataset = evaluator.fetch_and_preprocess_real_time_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step\n",
      "[2024-11-27 11:55:10,963: INFO: model_evaluation_mlflow: Real-time model testing complete.]\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluator.test_model_real_time(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[229.2669 ],\n",
       "       [229.27754],\n",
       "       [229.27519],\n",
       "       [229.26129],\n",
       "       [229.24379],\n",
       "       [229.22469],\n",
       "       [229.20555],\n",
       "       [229.1748 ],\n",
       "       [229.09624],\n",
       "       [229.0237 ],\n",
       "       [228.9746 ],\n",
       "       [228.89398],\n",
       "       [228.84634],\n",
       "       [228.8234 ],\n",
       "       [228.83284],\n",
       "       [228.84085],\n",
       "       [228.83073],\n",
       "       [228.80841],\n",
       "       [228.81808],\n",
       "       [228.83525],\n",
       "       [228.85638],\n",
       "       [228.879  ],\n",
       "       [228.8928 ],\n",
       "       [228.90788],\n",
       "       [228.92287],\n",
       "       [228.93721],\n",
       "       [228.9383 ],\n",
       "       [228.9379 ],\n",
       "       [228.9264 ],\n",
       "       [228.92313],\n",
       "       [228.92561],\n",
       "       [228.90689],\n",
       "       [228.87488],\n",
       "       [228.85167],\n",
       "       [228.84369],\n",
       "       [228.84671],\n",
       "       [228.8326 ],\n",
       "       [228.80748],\n",
       "       [228.79488],\n",
       "       [228.79744]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_price = predictions[-1]  # Last prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.79744"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_price[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"next_price: {next_price}\")\n",
    "st.write(f\"**Predicted Stock Price for Next Period:** ${next_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next stock price\n",
    "st.subheader(\"Predicted Next Stock Price\")\n",
    "try:\n",
    "    scaled_data, dataset = evaluator.fetch_and_preprocess_real_time_data()\n",
    "    predictions = evaluator.test_model_real_time(scaled_data)\n",
    "    next_price = predictions[-1]  # Last prediction\n",
    "    print(f\"next_price: {next_price}\")\n",
    "    st.write(f\"**Predicted Stock Price for Next Period:** ${next_price:.2f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error predicting next stock price: {e}\")\n",
    "    st.error(\"Could not predict the next stock price. Check the logs for details.\")\n",
    "\n",
    "# Model Evaluation and Logging\n",
    "st.subheader(\"Model Evaluation Metrics\")\n",
    "try:\n",
    "    # Perform model evaluation\n",
    "    rmse, test_predictions = evaluator.test_model(scaled_data, len(dataset), dataset)\n",
    "\n",
    "    # Display RMSE\n",
    "    st.write(f\"**Root Mean Square Error (RMSE):** {rmse:.2f}\")\n",
    "\n",
    "    # Log metrics and model to MLflow\n",
    "    evaluator.log_to_mlflow(rmse=rmse, predictions=test_predictions)\n",
    "    st.success(\"Model metrics and artifact logged to MLflow successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during model evaluation and logging: {e}\")\n",
    "    st.error(\"Could not evaluate the model or log to MLflow. Check the logs for details.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOpsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
